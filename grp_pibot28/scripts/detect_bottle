#!/usr/bin/python3
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from std_msgs.msg import String
from geometry_msgs.msg import Point  # Importation du message Point
from cv_bridge import CvBridge
import pyrealsense2 as rs
import numpy as np
import math
import cv2
from skimage.measure import label, regionprops


class BottleDetectorNode(Node):
    def __init__(self):
        super().__init__('bottle_detector_node')
        
        # Initialisation de la caméra RealSense
        self.pipeline = rs.pipeline()
        self.config = rs.config()
        self.colorizer = rs.colorizer()
        self.config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
        self.config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)

        self.pipeline.start(self.config)
        self.align_to = rs.stream.depth
        self.align = rs.align(self.align_to)

        # Initialisation des informations sur les bouteilles détectées
        self.detected_bottles = {}
        self.bottle_id = 1
        self._bridge = CvBridge()

        # Création des publishers
        self.string_publisher = self.create_publisher(String, 'bottle_detection', 10)
        self.marker_publisher = self.create_publisher(Point, 'marker_to_place', 10)

        # Création d'un timer pour traiter les images en continu
        self.timer = self.create_timer(0.1, self.process_frame_callback)

        self.get_logger().info("Nœud de détection de bouteilles initialisé !")

    def pixel_to_real_size(self, pixel_size, depth, intrinsics):
        # Conversion de la taille en pixels à la taille réelle avec les paramètres de la caméra
        fx = intrinsics.fx
        fy = intrinsics.fy
        return (pixel_size * depth) / fx, (pixel_size * depth) / fy

    def process_frame_callback(self):
        try:
            frames = self.pipeline.wait_for_frames()
            aligned_frames = self.align.process(frames)
            depth_frame = aligned_frames.get_depth_frame()
            aligned_color_frame = aligned_frames.get_color_frame()

            if not depth_frame or not aligned_color_frame:
                return

            # Conversion des images en format numpy
            color_image = np.asanyarray(aligned_color_frame.get_data())
            depth_colormap = np.asanyarray(self.colorizer.colorize(depth_frame).get_data())
            hsv_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2HSV)
            lo, hi = np.array([35, 100, 50]), np.array([85, 255, 255]) 
            # Limites de couleur verte
            mask = cv2.inRange(hsv_image, lo, hi)

            # Réduction du bruit avec des opérations morphologiques
            mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((5, 5), np.uint8))

            # Détection des régions connectées
            label_img = label(mask)
            regions = regionprops(label_img)

            for props in regions:
                if props.area < 100:  # Réduction du seuil pour détecter des régions plus petites
                    continue

                # Calculer les coordonnées du centre de la région et la profondeur
                minr, minc, maxr, maxc = props.bbox
                x, y = int((minc + maxc) / 2), int((minr + maxr) / 2)
                depth = depth_frame.get_distance(x, y)

                # Augmentation de la portée maximale
                if depth <= 0 or depth > 2:  
                    continue

                # Conversion des dimensions en tailles réelles
                height, width = maxr - minr, maxc - minc
                color_intrin = aligned_color_frame.profile.as_video_stream_profile().intrinsics
                real_height_y = self.pixel_to_real_size(height, depth, color_intrin)[0]
                real_width_x = self.pixel_to_real_size(width, depth, color_intrin)[0]   

                # Filtrer selon les dimensions réelles connues des bouteilles
                if not (0.205 - 0.04 <= real_height_y <= 0.205 + 0.04) or not (0.065 - 0.02 <= real_width_x <= 0.105 + 0.02):
                    continue

                # Vérification du ratio d'aspect
                aspect_ratio = real_height_y / real_width_x
                if not (1.5 <= aspect_ratio <= 4.0):  # Ratio adapté pour des bouteilles vues de loin
                    continue

                # Conversion en coordonnées 3D
                dx, dy, dz = rs.rs2_deproject_pixel_to_point(color_intrin, [x, y], depth)

                # Vérifier si c'est une nouvelle bouteille
                found = False
                for _, detected_position in self.detected_bottles.items(): 
                    dist = math.sqrt(
                        (detected_position[0] - dx) ** 2 +
                        (detected_position[1] - dy) ** 2 +
                        (detected_position[2] - dz) ** 2
                    )
                    if dist < 0.03:  # Distance augmentée pour inclure des erreurs liées à des objets éloignés
                        found = True
                        break

                # Publier une nouvelle détection si la bouteille est nouvelle
                if not found:
                    self.detected_bottles[self.bottle_id] = (dx, dy, dz)

                    # Publier sur le topic 'marker_to_place'
                    point_msg = Point()
                    point_msg.x = dx
                    point_msg.y = dy
                    point_msg.z = dz
                    self.marker_publisher.publish(point_msg)

                    # Publier sur le topic 'bottle_detection'
                    msg = String()
                    msg.data = f"Bouteille {self.bottle_id} détectée à (x={dx:.2f}, y={dy:.2f}, z={dz:.2f})"
                    self.string_publisher.publish(msg)
                    self.get_logger().info(msg.data)

                    self.bottle_id += 1

                # Visualisation des résultats
                cv2.rectangle(color_image, (minc, minr), (maxc, maxr), (0, 255, 0), 2)
                cv2.putText(color_image, f"ID: {self.bottle_id - 1}", (minc, minr - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
                cv2.putText(color_image, f"Profondeur: {depth:.2f}m", (minc, maxr + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)

            # Afficher les images
            combined_image = np.hstack((color_image, depth_colormap))
            cv2.imshow("Détection de bouteilles", combined_image)
            cv2.waitKey(1)

        except Exception as e:
            self.get_logger().error(f"Erreur lors du traitement des images : {e}")

    def destroy_node(self):
        # Arrêter la caméra
        self.pipeline.stop()
        cv2.destroyAllWindows()
        super().destroy_node()



def main():
    rclpy.init()
    node = BottleDetectorNode()
    rclpy.spin(node)
    node.destroy_node()
    rclpy.shutdown()


if __name__ == '__main__':
    main()
