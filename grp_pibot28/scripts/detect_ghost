#!/usr/bin/python3
import rclpy
import os
from ament_index_python.packages import get_package_share_directory
from rclpy.node import Node
from sensor_msgs.msg import Image
from std_msgs.msg import String
from geometry_msgs.msg import Point
from cv_bridge import CvBridge
import pyrealsense2 as rs
import numpy as np
import math
from ultralytics import YOLO
import sys, cv2


# Récupérer le chemin d'installation du package ROS2
package_name = "grp_pibot28"
package_share_dir = get_package_share_directory(package_name)

# Construire le chemin vers le fichier de poids
weights_path = os.path.join(package_share_dir, "include/ia_image_detection/runs/detect/train5/weights/last.pt")

# Vérifier si le fichier existe
if not os.path.exists(weights_path):
    raise FileNotFoundError(f"Le fichier de poids n'a pas été trouvé : {weights_path}")

# Charger le modèle
model = YOLO(weights_path)
threshold = 0.5


class GhostDetectorNode(Node):
    def __init__(self):
        super().__init__('ghost_detector_node')
        # self.detected_ghosts = {}
        # self.ghost_id = 1
        self._bridge = CvBridge()
        self.pipeline = None
        self.config = None
        self.colorizer = None
        self.align = None
        self.color_image = None

    def initializeROSnode(self):
        # Initialisation de la caméra RealSense
        self.pipeline = rs.pipeline()
        self.config = rs.config()
        self.colorizer = rs.colorizer()
        self.config.enable_stream(rs.stream.depth, 848, 480, rs.format.z16, 60)
        self.config.enable_stream(rs.stream.color, 848, 480, rs.format.bgr8, 60)

        self.pipeline.start(self.config)
        self.align_to = rs.stream.depth
        self.align = rs.align(self.align_to)

        # Création des publishers
        self.marker_publisher = self.create_publisher(Point, '/marker_to_place', 10)

        # Création d'un timer pour traiter les images en continu
        self.timer = self.create_timer(0.1, self.process_frame_callback)

        self.get_logger().info("Nœud de détection de Ghost initialisé !")



    def process_frame_callback(self):
        try:
            frames = self.pipeline.wait_for_frames()
            aligned_frames = self.align.process(frames)
            depth_frame = aligned_frames.get_depth_frame()
            aligned_color_frame = aligned_frames.get_color_frame()
            
            if not depth_frame or not aligned_color_frame:
                return

            self.color_image = np.asanyarray(aligned_color_frame.get_data())
            depth_colormap = np.asanyarray(self.colorizer.colorize(depth_frame).get_data())
            hsv_image = cv2.cvtColor(self.color_image, cv2.COLOR_BGR2HSV)
            
            frame = self.color_image
        
            results = model(frame)[0]
            for result in results.boxes.data.tolist():
                x1, y1, x2, y2, score, class_id = result
                if score > threshold:
                    if int(class_id) == 0:
                        
                        x_on_screen = (x1 + x2) / 2
                        y_on_screen = (y1 + y2) / 2
                        
                        if x_on_screen < 150 or x_on_screen > 650:
                            return
                        
                        if y_on_screen < 150 or y_on_screen > 300:
                            return
                        
                        depth = depth_frame.get_distance(int(x_on_screen), int(y_on_screen))
            
                        if depth <= 0.2 or depth > 2:
                            return

                        color_intrin = aligned_color_frame.profile.as_video_stream_profile().intrinsics
                        dx, dy, dz = rs.rs2_deproject_pixel_to_point(color_intrin, [x_on_screen, y_on_screen], depth)
                        ghost_x = depth
                        ghost_y = dx
                        ghost_z = dy
                        
                        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)
                        cv2.putText(frame, results.names[int(class_id)].upper(), 
                            (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)
                        cv2.putText(self.color_image, f"Profondeur: {depth:.2f}m", (int(x1), int(y2) + 20),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
                        
                        point_msg = Point()
                        point_msg.x = ghost_x
                        point_msg.y = ghost_y
                        point_msg.z = ghost_z
                        self.marker_publisher.publish(point_msg)

                        self.get_logger().info(f"Fantome détecté /// x = {ghost_x}  y = {ghost_y}  z = {ghost_z}")  

            # Display the images or further processing
            cv2.namedWindow('RealSense', cv2.WINDOW_AUTOSIZE)
            cv2.imshow("1", frame)
            cv2.waitKey(1)
                    

        except Exception as e:
            self.get_logger().error(f"Erreur lors du traitement des images : {e}")


    def destroy_node(self):
        self.pipeline.stop()
        cv2.destroyAllWindows()
        super().destroy_node()


def main():
    rclpy.init()
    node = GhostDetectorNode()
    node.initializeROSnode()
    rclpy.spin(node)
    node.destroy_node()
    rclpy.shutdown()


if __name__ == '__main__':
    main()